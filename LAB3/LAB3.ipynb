{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS405 Machine Learning: Lab 2 Preliminary\n",
    "### Name: 车凯威\n",
    "### ID: 12032207"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objectives__：Text mining (deriving information from text) is a wide field which has\n",
    "gained popularity with the huge text data being generated. Automation of a\n",
    "number of applications like sentiment analysis, document classification, topic classification, text summarization, machine translation, etc., has been\n",
    "done using machine learning models. In this lab, you are required to write\n",
    "your spam filter by using naïve Bayes method. This time you should not\n",
    "use 3\n",
    "rd party libraries including scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction:\n",
    "Spam filtering is a beginner’s example of document classification task\n",
    "which involves classifying an email as spam or non-spam (a.k.a. ham) mail. Email dataset will be provided. We will walk through the following steps\n",
    "to build this application:  \n",
    "1) Preparing the text data  \n",
    "2) Creating word dictionary  \n",
    "3) Feature extraction process  \n",
    "4) Training the classifier  \n",
    "5) Checking the results on test set  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preparing the text data:\n",
    "The data-set used here, is split into a training set and a test set containing\n",
    "702 mails and 260 mails respectively, divided equally between spam and\n",
    "ham mails. You will easily recognize spam mails as it contains *spmsg*\n",
    "in its filename.\n",
    "\n",
    "In any text mining problem, text cleaning is the first step where we\n",
    "remove those words from the document which may not contribute to the\n",
    "information we want to extract. Emails may contain a lot of undesirable\n",
    "characters like punctuation marks, stop words, digits, etc which may not\n",
    "be helpful in detecting the spam email. The emails in Ling-spam corpus\n",
    "have been already preprocessed in the following ways:  \n",
    "\n",
    "a) Removal of stop words – Stop words like “and”, “the”, “of”, etc are\n",
    "very common in all English sentences and are not very meaningful in\n",
    "deciding spam or legitimate status, so these words have been removed\n",
    "from the emails.   \n",
    "\n",
    "b) Lemmatization – It is the process of grouping together the different\n",
    "inflected forms of a word so they can be analysed as a single item. For\n",
    "example, “include”, “includes,” and “included” would all be\n",
    "represented as “include”. The context of the sentence is also preserved\n",
    "in lemmatization as opposed to stemming (another buzz word in text\n",
    "mining which does not consider meaning of the sentence)  \n",
    "\n",
    "We still need to remove the non-words like punctuation marks or special\n",
    "characters from the mail documents. There are several ways to do it. Here, we will remove such words after creating a dictionary, which is a very\n",
    "convenient method to do so since when you have a dictionary; you need\n",
    "to remove every such word only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def make_Dictionary(train_dir):\n",
    "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]    \n",
    "    all_words = []       \n",
    "    for mail in emails:    \n",
    "        with open(mail) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    all_words += words\n",
    "    \n",
    "    dictionary = Counter(all_words)\n",
    "    \n",
    "    list_to_remove = list(dictionary)\n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha() == False: \n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary\n",
    "    \n",
    "def extract_features(mail_dir): \n",
    "    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "    features_matrix = np.zeros((len(files),3000))\n",
    "    docID = 0\n",
    "    for fil in files:\n",
    "      with open(fil) as fi:\n",
    "        for i,line in enumerate(fi):\n",
    "          if i == 2:\n",
    "            words = line.split()\n",
    "            for word in words:\n",
    "              wordID = 0\n",
    "              for i,d in enumerate(dictionary):\n",
    "                if d[0] == word:\n",
    "                  wordID = i\n",
    "                  features_matrix[docID,wordID] = words.count(word)\n",
    "        docID = docID + 1     \n",
    "    return features_matrix\n",
    "    \n",
    "# Create a dictionary of words with its frequency\n",
    "\n",
    "train_dir = 'ling-spam\\\\train-mails'\n",
    "dictionary = make_Dictionary(train_dir)\n",
    "\n",
    "# Prepare feature vectors per training mail and its labels\n",
    "\n",
    "train_labels = np.zeros(702)\n",
    "train_labels[351:701] = 1\n",
    "train_matrix = extract_features(train_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_true = 350/702\n",
    "P_false = 1-P_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49416342412451364"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P_Feature_true = \n",
    "len(train_matrix[:,1])\n",
    "len(train_matrix[:,1][351:701])\n",
    "feature_all = sum(train_matrix[:,80])\n",
    "feature_true = sum(train_matrix[:,80][351:701])\n",
    "feature_false = feature_all-feature_true\n",
    "feature_true/feature_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_algorithm(train_matrix):\n",
    "    p_feature_true = []\n",
    "    p_feature_false = []\n",
    "    for feature_row_idx in range(0,len(train_matrix[1,:])):\n",
    "        #print(feature_row_idx)\n",
    "        feature_row = train_matrix[:,feature_row_idx]\n",
    "        ture_list = list(feature_row[351:701])\n",
    "        ture_all = sum(ture_list)+ture_list.count(0)\n",
    "        feature_true = sum(ture_list)\n",
    "\n",
    "        false_list = list(feature_row[0:350])\n",
    "        false_all = sum(false_list)+false_list.count(0)\n",
    "        feature_false = sum(false_list)\n",
    "\n",
    "\n",
    "        p_feature_true.append(feature_true/ture_all)\n",
    "        p_feature_false.append(feature_false/false_all) \n",
    "\n",
    "        \n",
    "    return p_feature_true,p_feature_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "def pred(test_matrix,p_feature_true,p_feature_false):\n",
    "    email = test_matrix[22,:]\n",
    "    email_true = []\n",
    "    email_false = []\n",
    "    for i,line in enumerate(email):\n",
    "        if (email[i]!=0)&(p_feature_true[i]!=0) :\n",
    "            email_true.append(p_feature_true[i]**email[i])\n",
    "            email_false.append(p_feature_true[i]**email[i])\n",
    "            \n",
    "\n",
    "    prb_true = reduce(lambda x,y:x*y,email_true)*P_true\n",
    "    prb_false = reduce(lambda x,y:x*y,email_false)*P_false\n",
    "\n",
    "    if prb_true > prb_false:\n",
    "        result = \"true\"\n",
    "    else:\n",
    "        result = \"false\"\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_algorithm' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fb778703e187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp_feature_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_feature_false\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_feature_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_feature_false\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_algorithm' is not defined"
     ]
    }
   ],
   "source": [
    "p_feature_true,p_feature_false = train_algorithm(train_matrix)\n",
    "pred(test_matrix,p_feature_true,p_feature_false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in train_matrix[:]:\n",
    "    x = x+1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_algorithm2(train_matrix):\n",
    "    p_feature_true = []\n",
    "    p_feature_false = []\n",
    "    \n",
    "\n",
    "    size = len(train_matrix[1,:])\n",
    "    \n",
    "\n",
    "    for feature_row_idx in range(0,size):\n",
    "        #print(feature_row_idx)\n",
    "        feature_row = train_matrix[:,feature_row_idx]\n",
    "        feature_row_plus1 = feature_row + 1\n",
    "        \n",
    "        ture_list = list(feature_row_plus1[351:701])\n",
    "        true_all = 352\n",
    "        feature_true = 352 - ture_list.count(1) +1\n",
    "\n",
    "        false_list = list(feature_row_plus1[0:350])\n",
    "        false_all = 352\n",
    "        feature_false = 352 - false_list.count(1) +1\n",
    "\n",
    "        p_feature_true.append(feature_true/true_all)\n",
    "        p_feature_false.append(feature_false/false_all) \n",
    "        #print(p_feature_false)\n",
    "        \n",
    "    return p_feature_true,p_feature_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_feature_true,p_feature_false = train_algorithm2(train_matrix)\n",
    "# p_feature_true.count(1)\n",
    "# feature_row = train_matrix[:,1]\n",
    "# feature_row_plus1 = feature_row + 1\n",
    "# list(feature_row_plus1).count(0)\n",
    "# p_feature_true.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "def pred2(test_matrix,p_feature_true,p_feature_false,idx):\n",
    "\n",
    "    p_feature_true = np.log(p_feature_true)\n",
    "    p_feature_false = np.log(p_feature_false)\n",
    "\n",
    "    email = test_matrix[idx,:] +1\n",
    "    email_true = []\n",
    "    email_false = []\n",
    "\n",
    "\n",
    "\n",
    "    # for i,line in enumerate(email):\n",
    "    #     email_true.append( * [i])\n",
    "    #     email_false.append(p_feature_false[i])\n",
    "    #     #p1 = np.log()\n",
    "\n",
    "    prb_true = sum(email * p_feature_true) + np.log(P_true)\n",
    "    prb_false = sum(email * p_feature_false) + np.log(P_false)\n",
    "\n",
    "    if prb_true > prb_false:\n",
    "        result = \"true\"\n",
    "    else:\n",
    "        result = \"false\"\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "# for i in range(130,131):\n",
    "pred2(test_matrix,p_feature_true,p_feature_false,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_algorithm3(train_matrix):\n",
    "    p_feature_true = []\n",
    "    p_feature_false = []\n",
    "    \n",
    "    for i in range(0,3000):\n",
    "        #print(feature_row_idx)\n",
    "        feature_row = train_matrix[:,i] + 1\n",
    "        \n",
    "        ture_list = list(feature_row[351:701])\n",
    "        \n",
    "        true_all = sum(ture_list) + 2\n",
    "        feature_true = sum(ture_list) - ture_list.count(1) + 1\n",
    "\n",
    "        false_list = list(feature_row[0:350])\n",
    "        false_all = sum(false_list) + 2\n",
    "        feature_false = sum(false_list) - false_list.count(1) + 1\n",
    "\n",
    "        p_feature_true.append(np.log(feature_true/true_all))\n",
    "        p_feature_false.append(np.log(feature_false/false_all)) \n",
    "        #print(p_feature_false)\n",
    "        \n",
    "    return p_feature_true,p_feature_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "444796,\n -2.5489062326209613,\n -0.6253513275520677,\n -1.9049837213460958,\n -1.0670069492527785,\n -1.058982493897342,\n -1.4033057069464272,\n -1.4085449700547104,\n -1.3960505360652553,\n -0.8696764166493955,\n -2.128231705849268,\n -1.6069030568309124,\n -2.1427363920521496,\n -1.6019096460133087,\n -3.6777061535158113,\n -0.8378191164326598,\n -2.5489062326209613,\n -1.3648394261186312,\n -3.9262076404201025,\n -1.3461472931064786,\n -1.3417383395696578,\n -1.3502760619307348,\n -1.6782481188369747,\n -1.0722949803507362,\n -0.7068931014645804,\n -2.136136885356381,\n -1.2944868118667678,\n -2.8553749158590684,\n -1.3814750746839417,\n -1.0743553110225497,\n -3.3155836289391636,\n -0.8406928165592796,\n -1.8127026430732982,\n -5.863631175598097,\n -0.9770570870903027,\n -1.4894785973551214,\n -2.31867123074567,\n -2.7300291078209855,\n -1.629743178594846,\n -0.7593699671730811,\n -0.8119130172782368,\n -1.8782999255591115,\n -1.252762968495368,\n -5.863631175598097,\n -2.008345619996106,\n -1.2146844599208637,\n -1.1193742801165387,\n -1.1955404048013383,\n -1.08293447594888,\n -1.3551541203841675,\n -5.863631175598097,\n -1.577611480822423,\n -1.164922289454063,\n -1.9101920664532341,\n -3.929020581796717,\n -0.640037355245997,\n -0.7411563997463059,\n -2.082097585737952,\n -1.4033057069464272,\n -1.7060276829440504,\n -1.002730516964827,\n -1.1721748558451264,\n -1.7202123179360067,\n -1.717651497074333,\n -1.2079020824658255,\n -1.6689638917481273,\n -1.6773491180503108,\n -1.5141277326297755,\n -2.124601937798689,\n -1.4622802680978126,\n -1.2031850925876868,\n -3.3155836289391636,\n -1.8021222562636017,\n -1.985545455912709,\n -2.414289082574047,\n -1.3350010667323402,\n -1.4316421810983497,\n -1.4433110415601265,\n -1.9101920664532341,\n -1.986292486500999,\n -3.3956263366127,\n -2.038619547159581,\n -0.8042515373970236,\n -2.191919525106526,\n -1.592002850611999,\n -5.863631175598097,\n -1.6347557204183902,\n -0.9822486996659525,\n -1.8692347813963457,\n -2.063693184711697,\n -0.9946991008758768,\n -0.8411565923651211,\n -2.030776369698555,\n -1.4083270761197733,\n -2.479515801153124,\n -1.060391075847912,\n -1.9538153285624267,\n -1.5751208195099713,\n -0.7929117107136504,\n -0.956836826268505,\n -3.175272187386069,\n -3.7954891891721947,\n -3.3956263366127,\n -1.9459101490553135,\n -1.1054851679558717,\n -1.913366601322842,\n -1.480605040591132,\n -2.8986705607108596,\n -1.972507461574579,\n -4.259859000699674,\n -3.9262076404201025,\n -1.7691169924782952,\n -1.5240780634829436,\n -0.8952373226763227,\n -2.41699544417179,\n -0.906034231706966,\n -0.9665525666550434,\n -1.599387576580599,\n -4.767855768265187,\n -0.8505840940380223,\n -1.7968745698948254,\n -1.4647163228956939,\n -2.761659651707591,\n -3.3984157387002787,\n -0.8929037991760013,\n -2.575878427993727,\n -1.672285816093764,\n -3.1780538303479458,\n -2.332683124151325,\n -1.672285816093764,\n -2.6837575085331653,\n -3.488208758651785,\n -0.7522877556038852,\n -2.0057105723581006,\n -4.767855768265187,\n -3.3956263366127,\n -1.2172698324694256,\n -1.2818912414183916,\n -1.1286723554739106,\n -5.863631175598097,\n -1.8704975452749266,\n -1.6272274539975988,\n -1.5348112232288929,\n -2.6864860231863696,\n -1.117088564835683,\n -1.8588987720656835,\n -1.0859538917961862,\n -1.3335902976293221,\n -1.1568359489470064,\n -2.082097585737952,\n -2.191919525106526,\n -1.7111297348279457,\n -0.9152749877543196,\n -1.3698039992204751,\n -0.9521057371804535,\n -3.1780538303479458,\n -0.946596081369484,\n -0.8621129461723442,\n -2.3160081133261863,\n -1.3668762752627892,\n -1.616818019731723,\n -4.483002552013883,\n -0.8840947920736673,\n -1.9777430756285241,\n -1.7414976344471669,\n -1.3223456365196171,\n -1.2946100784308683,\n -1.7047480922384253,\n -1.4355654101266735,\n -2.721843523234546,\n -1.8614928072427301,\n -1.791759469228055,\n -1.4884238561962704,\n -2.160378303950253,\n -2.145399509471633,\n -1.4360558706789543,\n -2.3133378847703074,\n -2.0360119837524997,\n -1.6510595871249198,\n -1.3982419345410089,\n -1.2237754316221157,\n -2.4450607412408005,\n -1.986292486500999,\n -2.2606941512848855,\n -1.2496749578067916,\n -0.9069205435865704,\n -1.8475508288564706,\n -0.9967630850967282,\n -1.5587636214708336,\n -1.1278607177943418,\n -2.1229266536195746,\n -2.0900236510103727,\n -2.7245795030534206,\n -0.9765829621302752,\n -2.2353763433005955,\n -4.767855768265187,\n -1.555635206441124,\n -1.619513564422842,\n -1.2134515482804797,\n -1.4622802680978126,\n -1.1470646720540565,\n -2.479515801153124,\n -1.592002850611999,\n -1.44873661445765,\n -2.6418008155610093,\n -2.0952730068965164,\n -4.259859000699674,\n -1.2922654114716141,\n -3.1135153092103742,\n -1.151509234790195,\n -1.7111297348279457,\n -1.8901995420413076,\n -2.6418008155610093,\n -2.4477671028385437,\n -3.798294240099803,\n -1.3911843464140825,\n -1.7136710322566184,\n -1.4182774069729414,\n -1.3025244780544318,\n -1.7111297348279457,\n -2.2553322081435,\n -2.9014215940827497,\n -1.2583715081549776,\n -1.4631599414187548,\n -1.463255402256019,\n -2.9472052326593308,\n -3.3956263366127,\n -1.8562979903656263,\n -2.0255131996542803,\n -2.389841537991274,\n -1.5040773967762742,\n -1.6193882432872684,\n -1.175758961881994,\n -1.672285816093764,\n -2.3871424810221087,\n -1.122604715411331,\n -1.825572833593833,\n -3.247046701834897,\n -1.6506808709681495,\n -1.833216182906401,\n -4.767855768265187,\n -5.863631175598097,\n -0.9607424944449888,\n -1.8371611250073347,\n -1.5379789484519555,\n -2.849880396541428,\n -1.8449635052915196,\n -1.1464029525044581,\n -1.2594370755830613,\n -2.1945755691646425,\n -2.1427363920521496,\n -3.1135153092103742,\n -1.3862943611198906,\n -1.9967912705992186,\n -3.1162892360931,\n -1.501605207630885,\n -1.5125880864441827,\n -2.1657259102768482,\n -4.259859000699674,\n -3.9262076404201025,\n -2.849880396541428,\n -2.5731573378793664,\n -1.5705980791178364,\n -1.7404661748405046,\n -4.767855768265187,\n -3.9262076404201025,\n -1.4238457067720232,\n -1.1210347527239422,\n -1.592002850611999,\n -2.2713325494899412,\n -1.1454592619648984,\n -1.0741937613199637,\n -2.479515801153124,\n -1.708581962749147,\n -1.4161473242695717,\n -1.2084074013938018,\n -1.7385677404782116,\n -3.0611894902086347,\n -1.267280253044087,\n -1.3536574318068681,\n -1.4192504488031863,\n -1.682386912080268,\n -5.863631175598097,\n -1.8120647353888004,\n -2.1972245773362196,\n -2.1683890276963322,\n -2.5041644663924147,\n -1.9590509426163716,\n -3.6777061535158113,\n -3.24426505887302,\n -5.863631175598097,\n -1.9101920664532341,\n -1.1786549963416462,\n -1.4709882399691578,\n -2.218673120743703,\n -2.5704288232261625,\n -1.2619373447714093,\n -1.4200325007517407,\n -1.5339303599259553,\n -2.384436119424366,\n -2.1586097412084397,\n -2.1683890276963322,\n -1.7866961672715083,\n -2.145399509471633,\n -1.8312903079846903,\n -1.3724373264584644,\n -1.3317353768694562,\n -1.32513993796656,\n -1.253887195707649,\n -3.9262076404201025,\n -1.852705479445135,\n -2.1630556817209694,\n -2.727308017706625,\n -1.5191152741408145,\n -1.7422444047006744,\n -1.2195981222290169,\n -1.672285816093764,\n -3.3155836289391636,\n -1.7440716384423396,\n -2.0057105723581006,\n -1.2246870087134993,\n -1.8928003237413649,\n -1.2656663733312759,\n -3.0012724539296065,\n -1.791759469228055,\n -2.160378303950253,\n -1.8953943589184115,\n -1.8808872491240622,\n -1.4493669645749656,\n -2.28399225991743,\n -3.6777061535158113,\n -1.4613619341533133,\n -2.103603790958916,\n -1.4873904779912595,\n -1.717651497074333,\n -1.1994169877900753,\n -2.3608540011180215,\n -2.764403137653342,\n -2.5407871081824567,\n -1.5028556495259517,\n -2.6837575085331653,\n -5.863631175598097,\n -1.557539474306449,\n -1.6247053845648889,\n -2.681021528714291,\n -3.055664614276665,\n -3.9262076404201025,\n -2.0228711901914416,\n -2.128231705849268,\n -1.7543019066931547,\n -4.259859000699674,\n -5.863631175598097,\n -1.2062956857420757,\n -1.32580559963924,\n -1.6094379124341003,\n -1.5743465926228302,\n -2.4250708581773353,\n -3.1780538303479458,\n -4.767855768265187,\n -1.3509549946745818,\n -2.0360119837524997,\n -1.3259512312124222,\n -1.7866180697276364,\n -1.9751286950544533,\n -2.606796467397037,\n -1.414465238086587,\n -3.3984157387002787,\n -1.6833501707208702,\n -1.5241845200753688,\n -1.3429580476329226,\n -1.4287476773722299,\n -5.863631175598097,\n -1.8127026430732982,\n -1.5177167898695927,\n -1.8204446172269138,\n -2.3635457927837327,\n -1.6347557204183902,\n -2.3133378847703074,\n -2.24865675096849,\n -3.4798405089812685,\n -3.058430867769555,\n -3.9262076404201025,\n -1.4531573063490173,\n -1.415853163361435,\n -3.3155836289391636,\n -2.455842516844089,\n -2.191919525106526,\n -2.806111414278425,\n -3.5751506887855933,\n -4.259859000699674,\n -3.929020581796717,\n -1.5880340037709468,\n -1.5040773967762742,\n -2.389841537991274,\n -2.575878427993727,\n -2.8553749158590684,\n -1.8044984950054848,\n -2.3608540011180215,\n -3.321154673988619,\n -1.3910002521573033,\n -3.055664614276665,\n -1.5111445639993666,\n -2.849880396541428,\n -1.519489675771161,\n -2.487591215158669,\n -2.476809439555381,\n -2.3871424810221087,\n -3.175272187386069,\n -1.55814461804655,\n -3.5751506887855933,\n -2.0457159069718,\n -5.863631175598097,\n -5.863631175598097,\n -1.5212136790192614,\n -2.1088948085933312,\n -3.175272187386069,\n -1.6170041528174162,\n -2.1533465711641653,\n -2.41699544417179,\n -1.5125880864441827,\n -2.8986705607108596,\n -3.180827757230671,\n -5.863631175598097,\n -2.455842516844089,\n -1.9380874233741041,\n -2.7191000372887952,\n -5.863631175598097,\n -1.8127026430732982,\n -1.79954160967011,\n -1.7866180697276364,\n -2.176336089388864,\n -2.806111414278425,\n -2.67827804276854,\n -2.6581055245859533,\n -3.9262076404201025,\n -4.767855768265187,\n -1.4203609156834969,\n -1.604487407274244,\n -2.0057105723581006,\n -1.5280533086519854,\n -3.6777061535158113,\n -2.761659651707591,\n -2.617666139633941,\n -2.9444389791664407,\n -1.9932874300663246,\n -1.833870954578182,\n -4.259859000699674,\n -1.7047480922384253,\n -2.0794415416798357,\n -3.247046701834897,\n -1.4227504030808782,\n -1.607054121078824,\n -1.5445892656931752,\n -2.998506200436716,\n -2.286669637688146,\n -2.082097585737952,\n -2.6040604875781623,\n -2.199866586799058,\n -1.943309367355256,\n -4.767855768265187,\n -4.483002552013883,\n -5.863631175598097,\n -1.6217080050259147,\n -2.849880396541428,\n -2.066335194174535,\n -1.884977598060156,\n -1.8588987720656835,\n -2.2318485419022673,\n -2.2606941512848855,\n -1.6094379124341003,\n -1.9698793391683096,\n -3.0528906873939397,\n -1.8466752268241697,\n -1.5280533086519854,\n -1.66363836933178,\n -2.4504661598077084,\n -2.681021528714291,\n -2.2407096892759584,\n -1.8678831647008558,\n -1.5894871260147516,\n -1.9153734251952317,\n -2.2106837307102243,\n -2.4115753767024506,\n -3.058430867769555,\n -3.0528906873939397,\n -1.678079845156264,\n -1.9538153285624267,\n -1.4796263009121098,\n -1.4849837379606945,\n -1.5623704015761146,\n -5.863631175598097,\n -1.5379789484519555,\n -2.1892564076870427,\n -2.3635457927837327,\n -1.817467825938262,\n -1.5226308046720218,\n -2.5041644663924147,\n -1.6697445186650914,\n -3.0528906873939397,\n -1.6401308588335066,\n -1.9407018039481752,\n -2.849880396541428,\n -3.058430867769555,\n -2.5407871081824567,\n -1.8669828904656425,\n -1.4845645825526923,\n -1.5926307941177191,\n -2.191919525106526,\n -2.606796467397037,\n -3.577947893406655,\n -1.619266001370363,\n -1.6714733033535532,\n -2.340736858958422,\n -2.1710450717544485,\n -1.8204446172269138,\n -2.1683890276963322,\n -2.4423470353692043,\n -2.67827804276854,\n -2.2813076945467605,\n -2.003068562895262,\n -1.3668762752627892,\n -1.9075912847531766,\n -2.998506200436716,\n -4.767855768265187,\n -5.863631175598097,\n -3.6805112044434196,\n -1.4919265789937615,\n -1.833870954578182,\n -1.65700632935321,\n -1.717651497074333,\n -2.7245795030534206,\n -1.6442673035757802,\n -3.9262076404201025,\n -3.7954891891721947,\n -1.4655184031725912,\n -1.988927534139004,\n -2.122001156098632,\n -1.5339303599259553,\n -1.6613976513648114,\n -1.501605207630885,\n -2.4450607412408005,\n -2.32998406718216,\n -1.8757058903820647,\n -2.7191000372887952,\n -4.767855768265187,\n -3.1135153092103742,\n -1.5686159179138452,\n -1.8046962602587746,\n -2.721843523234546,\n -1.5429050667880113,\n -2.395217895027654,\n -1.948552158518152,\n -3.0012724539296065,\n -2.5407871081824567,\n -1.5637019031114163,\n -1.6607312068216509,\n -1.5255564284533982,\n -1.9564365620423008,\n -2.808854900224176,\n -1.6267865507687134,\n -1.8072636557640203,\n -2.476809439555381,\n -3.3183730310267423,\n -1.599387576580599,\n -2.761659651707591,\n -2.998506200436716,\n -1.986292486500999,\n -1.7022196458850665,\n -2.606796467397037,\n -3.9262076404201025,\n -1.9459101490553135,\n -2.5068855565067754,\n -1.948552158518152,\n -2.009761621041846,\n -3.2498206287176226,\n -1.825572833593833,\n -2.4740957336837845,\n -3.004031076368686,\n -2.286669637688146,\n -3.9262076404201025,\n -4.767855768265187,\n -5.863631175598097,\n -1.7866180697276364,\n -2.030776369698555,\n -1.6344392146395177,\n -1.6582280766035324,\n -1.6588627957616235,\n -4.259859000699674,\n -3.3956263366127,\n -2.310660506999591,\n -2.94996385509841,\n -4.767855768265187,\n -4.767855768265187,\n -1.66571874833269,\n -1.6456175690116028,\n -1.6422277352570913,\n -1.7136710322566184,\n -2.4585198946148052,\n -2.7245795030534206,\n -2.258016773514169,\n -4.259859000699674,\n -2.223335721339905,\n -3.3956263366127,\n -4.080358320247361,\n -5.863631175598097,\n -1.9588135538912212,\n -2.4423470353692043,\n -1.892107443062337,\n -1.8666607774011728,\n -1.8808872491240622,\n -1.7466390339475855,\n -3.9262076404201025,\n -1.7237721282431222,\n -2.0588222544771004,\n -2.066335194174535,\n -1.7414976344471669,\n -4.080358320247361,\n -2.476809439555381,\n -2.9014215940827497,\n -5.863631175598097,\n -5.863631175598097,\n -2.681021528714291,\n -2.0978873874705872,\n -2.066335194174535,\n -1.6501560054528852,\n -2.9472052326593308,\n -3.4798405089812685,\n -2.849880396541428,\n -2.3052841499632106,\n -2.8986705607108596,\n -1.5772170334229374,\n -2.1630556817209694,\n -2.4330815819234144,\n -1.5995122726341304,\n -1.7414976344471669,\n -1.6739764335716716,\n -3.9262076404201025,\n -1.6372526006169774,\n -1.791759469228055,\n -3.3155836289391636,\n -3.4798405089812685,\n -2.6837575085331653,\n -3.1135153092103742,\n -4.767855768265187,\n -5.863631175598097,\n -5.863631175598097,\n -1.6094379124341003,\n -2.2813076945467605,\n -1.9661128563728327,\n -2.4740957336837845,\n -2.3742410819004807,\n -2.606796467397037,\n -1.8178706132317408,\n -1.8475508288564706,\n -1.8475508288564706,\n -2.5435008140540534,\n -2.655406467616788,\n -3.9262076404201025,\n -1.79954160967011,\n -2.5515980242866725,\n -3.24426505887302,\n -3.6777061535158113,\n -3.9262076404201025,\n -3.3956263366127,\n -5.863631175598097,\n -5.863631175598097,\n -1.6069347822159818,\n -1.988927534139004,\n -1.6019096460133087,\n -1.6563214983329508,\n -2.998506200436716,\n -2.0689702418125404,\n -1.6848963236856938,\n -1.7122952978738082,\n -2.3978952727983707,\n -2.0255131996542803,\n -3.9262076404201025,\n -3.3239286008713442,\n -1.6481524246147907,\n -1.6798711874830206,\n -1.951187206156157,\n -2.0057105723581006,\n -2.2080063529395075,\n -1.923095471289142,\n -1.7713505975968478,\n -1.817467825938262,\n -1.619642082608342,\n -2.7300291078209855,\n -3.2498206287176226,\n -4.483002552013883,\n -4.767855768265187,\n -3.3956263366127,\n -2.3608540011180215,\n -2.6418008155610093,\n -1.833216182906401,\n -1.7253143698199023,\n -1.7713505975968478,\n -2.3689077359251183,\n -1.7840374231341447,\n -1.7968745698948254,\n -4.767855768265187,\n -2.998506200436716,\n -3.3155836289391636,\n -5.863631175598097,\n -5.863631175598097,\n -2.122001156098632,\n -2.3160081133261863,\n -2.3079759416289223,\n -2.414289082574047,\n -1.9179540717887233,\n -2.6864860231863696,\n -2.67827804276854,\n -2.1972245773362196,\n -2.476809439555381,\n -4.259859000699674,\n -3.5751506887855933,\n -3.4798405089812685,\n -2.512305623976115,\n -1.882006347075833,\n -4.259859000699674,\n -2.7589086183357012,\n -3.4826377136023297,\n -5.863631175598097,\n -1.7741931455101558,\n -1.8588987720656835,\n -1.985545455912709,\n -2.575878427993727,\n -1.8562979903656263,\n -1.7162058878598065,\n -2.761659651707591,\n -1.7892310228746964,\n -3.055664614276665,\n -3.6777061535158113,\n -3.1780538303479458,\n -2.9444389791664407,\n -3.1135153092103742,\n -1.9873668627336594,\n -3.180827757230671,\n -3.9262076404201025,\n -1.9013483209954025,\n -3.055664614276665,\n -2.172223275130802,\n -2.9444389791664407,\n -2.1088948085933312,\n -3.4798405089812685,\n -2.0845306111873074,\n -2.176336089388864,\n -3.6777061535158113,\n -2.03688192726104,\n -1.8654770451246225,\n -3.4826377136023297,\n -3.7954891891721947,\n -3.6777061535158113,\n -3.9262076404201025,\n -5.863631175598097,\n -5.863631175598097,\n -5.863631175598097,\n -1.8666607774011728,\n -2.2813076945467605,\n -2.67827804276854,\n -2.0952730068965164,\n -2.1657259102768482,\n -2.5407871081824567,\n -3.9262076404201025,\n -3.055664614276665,\n -3.175272187386069,\n -2.4740957336837845,\n -1.86293574769595,\n -2.721843523234546,\n -3.4798405089812685,\n -2.145399509471633,\n -2.5407871081824567,\n -2.4383866341531073,\n -3.6777061535158113,\n -2.7671391174722166,\n -3.5751506887855933,\n -4.767855768265187,\n -4.259859000699674,\n -3.4826377136023297,\n -3.9262076404201025,\n -5.863631175598097,\n -4.259859000699674,\n -2.808854900224176,\n -2.2353763433005955,\n -2.127195972975736,\n -3.1135153092103742,\n -1.6808023986420713,\n -2.5407871081824567,\n -1.98813277947766,\n -1.9993988340062996,\n -2.4822148581222887,\n -2.1507045617013265,\n -3.4854271156899084,\n -2.2660274972602483,\n -1.9174476843915518,\n -2.2606941512848855,\n -4.259859000699674,\n -2.6418008155610093,\n -2.9472052326593308,\n -2.31867123074567,\n -4.767855768265187,\n -4.767855768265187,\n -5.863631175598097,\n -2.0588222544771004,\n -2.41699544417179,\n -2.761659651707591,\n -2.0228711901914416,\n -2.03688192726104,\n -1.961374374752895,\n -1.9564365620423008,\n -3.0611894902086347,\n -2.008345619996106,\n -3.3984157387002787,\n -3.1135153092103742,\n -2.847121774102348,\n -2.849880396541428,\n -1.796954286105159,\n -2.476809439555381,\n -2.4250708581773353,\n -2.998506200436716,\n -2.538066018068096,\n -3.3956263366127,\n -3.6777061535158113,\n -4.767855768265187,\n -1.9642592877235099,\n -2.3079759416289223,\n -2.3079759416289223,\n -3.1135153092103742,\n -2.276609606590785,\n -1.9536721543908024,\n -3.2525868822105126,\n -4.259859000699674,\n -3.3183730310267423,\n -2.3871424810221087,\n -2.847121774102348,\n -1.923095471289142,\n -3.3956263366127,\n -3.6833084090644808,\n -3.3956263366127,\n -4.259859000699674,\n -5.863631175598097,\n -2.3380594811877056,\n -2.2106837307102243,\n -2.3133378847703074,\n -1.9564365620423008,\n -1.8235081675426352,\n -2.2813076945467605,\n -2.3871424810221087,\n -2.2265991860161236,\n -1.8692347813963457,\n -2.2669579153508947,\n -4.259859000699674,\n -2.2207550747464135,\n -2.644536795379884,\n -2.3871424810221087,\n -4.080358320247361,\n -2.546207175651796,\n -3.0012724539296065,\n -4.080358320247361,\n -4.080358320247361,\n -3.4798405089812685,\n -2.1793897097001853,\n -4.767855768265187,\n -4.767855768265187,\n -5.863631175598097,\n -5.863631175598097,\n -5.863631175598097,\n -1.9616585060234524,\n -2.0457159069718,\n -2.0952730068965164,\n -2.9472052326593308,\n -2.5435008140540534,\n -2.1892564076870427,\n -1.8021222562636017,\n -2.191919525106526,\n -3.3956263366127,\n -2.1115298562313365,\n -2.0583881324820035,\n -2.1030957325777258,\n -2.223335721339905,\n -1.972021293058999,\n -2.3353749158170367,\n -3.1135153092103742,\n -4.483002552013883,\n -1.8588987720656835,\n -2.046401687601636,\n -3.0611894902086347,\n -4.259859000699674,\n -4.259859000699674,\n -2.8986705607108596,\n -3.4798405089812685,\n -2.3234191798968875,\n -4.767855768265187,\n -3.9318256327243257,\n -4.483002552013883,\n -5.863631175598097,\n -5.863631175598097,\n -5.863631175598097,\n -1.8953943589184115,\n -2.2660274972602483,\n -2.4250708581773353,\n -2.22132212891528,\n -2.681021528714291,\n -2.108277091319723,\n -2.5041644663924147,\n -2.644536795379884,\n -1.8536904269585452,\n -2.2433657333340746,\n -2.244852626325474,\n -2.178971137026869,\n -2.9041650800285006,\n -2.2813076945467605,\n -4.083171261623976,\n -2.103603790958916,\n -2.0457159069718,\n -2.849880396541428,\n -4.259859000699674,\n -2.1972245773362196,\n -2.129783296540687,\n -3.4798405089812685,\n -3.6833084090644808,\n -4.259859000699674,\n -5.863631175598097,\n -1.9127861016302807,\n -2.5704288232261625,\n -2.119393592691551,\n -2.581298495463066,\n -1.9564365620423008,\n -2.2080063529395075,\n ...]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# for i in range(130,131):\n",
    "\n",
    "p_feature_true,p_feature_false = train_algorithm3(train_matrix)\n",
    "\n",
    "#print(p_feature_true)\n",
    "#print(p_feature_false)\n",
    "p_feature_true\n",
    "p_feature_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "431"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "list(train_matrix[:,1]).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "def pred3(test_matrix,p_feature_true,p_feature_false,idx):\n",
    "    \n",
    "    email  = test_matrix[idx,:] + 1\n",
    "\n",
    "    # for i,line in enumerate(email):\n",
    "    #     email_true.append( * [i])\n",
    "    #     email_false.append(p_feature_false[i])\n",
    "    #     #p1 = np.log()\n",
    "\n",
    "    prb_true = sum(email * p_feature_true) + np.log(P_true)\n",
    "    prb_false = sum(email * p_feature_false) + np.log(P_false)\n",
    "    print(prb_true)\n",
    "    if prb_true > prb_false:\n",
    "        result=1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "    #print(prb_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-10009.622306941168\n-9859.956099473093\n-9945.72935953161\n-9798.707948525054\n-9868.9005890284\n-10189.417666746507\n-9971.646801861254\n-10178.322486401463\n-9718.833109872956\n-10301.397028969766\n-9798.734858439942\n-9857.478771322918\n-9765.977111775344\n-10337.1085072827\n-10077.436204713713\n-9739.088236369025\n-9760.882900336765\n-9723.631545467422\n-9954.6073288005\n-9734.499051001372\n-10121.988043494355\n-9989.450191470534\n-10924.642620158666\n-10387.652892714104\n-9905.531978564086\n-10668.612411372773\n-10823.548856513195\n-10155.879582940779\n-10148.28507350718\n-10043.111733554928\n-9864.114851807917\n-10655.158305421648\n-9747.19691142196\n-11580.634398277585\n-11681.830659051437\n-9771.812995127993\n-9875.20752555215\n-10347.07759052921\n-9728.166466002773\n-10152.978742265077\n-9977.46856822304\n-10259.223930549222\n-9878.37423242737\n-9776.561787614697\n-10086.983403707\n-9773.537174745552\n-10061.438246113792\n-9999.618063378246\n-9822.907461056171\n-9928.732127059307\n-10037.666888094833\n-9809.178250495273\n-9882.955904517488\n-9930.540412410135\n-9830.497754670636\n-10240.219204554975\n-9809.739172587073\n-9885.038735405275\n-9912.314613822644\n-10309.518946377924\n-10054.659548807953\n-10527.136610967347\n-9914.204679236502\n-10003.284003143292\n-10974.93649267472\n-11129.080765998922\n-9996.16265191803\n-9892.183356902722\n-10861.355119010514\n-10097.633624136299\n-9871.577259731606\n-9882.416309762146\n-9883.863688331228\n-10178.498564139276\n-10224.24563990588\n-9883.863688331228\n-10319.795924457581\n-10067.966994690001\n-10565.454340648284\n-11612.833959623596\n-11016.894602066848\n-9983.407738694917\n-10221.08955068107\n-10378.797591790308\n-10444.348438905714\n-10920.377775454755\n-9858.952807130705\n-10288.963481600156\n-9922.261234135362\n-11608.974600966576\n-10039.277271680088\n-10875.870084495073\n-9720.20893931171\n-10342.70031204671\n-10253.24288915083\n-9844.926585300005\n-9824.231700085058\n-10523.493266680658\n-9812.997777220296\n-10428.653671923606\n-10343.119398314771\n-9853.25899130402\n-10643.29028419228\n-11032.498395170376\n-9898.174552585266\n-9872.209066813806\n-9791.75515253852\n-10313.905800690149\n-10141.840942052955\n-9906.473733162304\n-10228.335729657074\n-10185.033368682978\n-9866.513106015751\n-9856.16083766323\n-9920.14310175565\n-10142.93773763547\n-9726.286530030196\n-10218.172189935463\n-9917.633800194151\n-9895.835380021583\n-10044.35041087698\n-10405.411002865769\n-10008.641298516122\n-9875.052757847943\n-9864.413892433533\n-9929.00319281053\n-10040.42427906715\n-10043.190994673849\n-10626.977153598998\n-9827.43136100244\n-10077.56772821322\n-9882.458500170338\n-9882.458500170338\n-9882.458500170338\n-9807.903976849972\n-10548.611601996141\n-10024.434262179813\n-9778.168413678686\n-9948.151913790016\n-10056.813531627657\n-10427.366288219957\n-9887.145485872079\n-9711.077644152032\n-10353.056635456602\n-9766.824331729651\n-10597.690461534996\n-14211.373658587763\n-10105.815890858352\n-9758.918497010167\n-10441.417726415348\n-9832.421124398772\n-10060.959191396701\n-9787.154241102826\n-10635.246726605195\n-9782.829805313208\n-9957.194514082183\n-9764.470060531785\n-9748.049376637611\n-9835.878881121373\n-9753.860451437238\n-9742.97880514304\n-9857.928932117638\n-9857.928932117638\n-9743.543199700662\n-9743.543199700662\n-9743.543199700662\n-9858.785726058142\n-9785.768689866134\n-9728.650439918221\n-9725.995560791327\n-9705.073068985675\n-9745.080105085466\n-9785.420276447596\n-9738.37152542079\n-9857.07197799128\n-10246.043641064953\n-10097.847758636186\n-9733.646202791868\n-12456.438970419842\n-9882.186899685463\n-13482.84275108201\n-11061.095837508788\n-11061.095837508788\n-10917.98922086761\n-11086.662400958809\n-9902.081913987096\n-9757.32548600783\n-10025.8663542431\n-9763.746114131785\n-10768.705154098518\n-9819.186081526937\n-9758.166123428153\n-9758.458696344926\n-10318.295826981443\n-10425.045081644548\n-9829.339246361294\n-11023.30222887086\n-10131.688889698084\n-9758.458696344926\n-10279.966280031098\n-9758.772367371512\n-10163.040225273258\n-9758.458696344926\n-9839.828905211594\n-9758.458696344926\n-11306.49984260337\n-9900.06676270772\n-9989.254204853316\n-9758.458696344926\n-9841.907714082494\n-9841.907714082494\n-10260.361800298184\n-9759.437464284014\n-9989.254204853316\n-10239.483414982848\n-9815.055207451727\n-9729.265704476991\n-10826.361002493108\n-10311.318622124074\n-10721.295308467368\n-9736.746212170856\n-9785.261108987143\n-9711.642457765965\n-10642.336073151511\n-9781.250188507716\n-9806.934723909235\n-10055.632854443218\n-9808.936971525925\n-9786.931712908628\n-10406.917575277144\n-9799.1781306571\n-9760.830436494427\n-9858.17113757413\n-9841.907714082494\n-9782.524872382579\n-9777.822040080204\n-10460.885269473805\n-10265.817992405746\n-9815.439521348753\n-9787.767237054732\n-9984.681368954902\n-9789.336119028016\n-10364.302397871108\n-9772.877565376015\n-10193.589585414753\n-9914.970063223089\n-9854.091959183697\n-9881.835072408008\n-9775.242014157147\n-10313.855368646997\n-9713.525087285147\n-9874.93240599944\n-9794.57793229369\n-10847.79782186136\n-10300.50821467088\n-9798.590929649616\n-10477.61320262855\n-9882.458500170338\n-9882.458500170338\n-11818.644485976025\n"
    }
   ],
   "source": [
    "#pred3(test_matrix,p_feature_true,p_feature_false,190)\n",
    "# email  = test_matrix[1,:] + 1\n",
    "# print(email)\n",
    "result = []\n",
    "for i in range(0,260):\n",
    "    result.append(pred3(test_matrix,p_feature_true,p_feature_false,i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[129   1]\n",
      " [  9 121]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9615384615384616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################\n",
    "# Training SVM and Naive bayes classifier and its variants\n",
    "\n",
    "#model1 = LinearSVC()\n",
    "model2 = MultinomialNB()\n",
    "\n",
    "#model1.fit(train_matrix,train_labels)\n",
    "model2.fit(train_matrix,train_labels)\n",
    "\n",
    "\n",
    "# Test the unseen mails for Spam\n",
    "\n",
    "test_dir = 'ling-spam\\\\test-mails'\n",
    "test_matrix = extract_features(test_dir)\n",
    "test_labels = np.zeros(260)\n",
    "test_labels[130:260] = 1\n",
    "\n",
    "#result1 = model1.predict(test_matrix)\n",
    "result2 = model2.predict(test_matrix)\n",
    "\n",
    "#print(confusion_matrix(test_labels,result1))\n",
    "print(confusion_matrix(test_labels,result2))\n",
    "\n",
    "correct = 0\n",
    "for i,item in enumerate(result2):\n",
    "    if result2[i]==test_labels[i]:\n",
    "        correct+=1\n",
    "correct\n",
    "acc = correct/260\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9192307692307692"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "for i,item in enumerate(result):\n",
    "    if result[i]==test_labels[i]:\n",
    "        correct+=1\n",
    "correct\n",
    "acc = correct/260\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}