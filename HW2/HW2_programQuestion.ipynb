{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Southern University of Science and Technology-Department of Computer Science and Engineering\n",
    "\n",
    "Course: Machine Learning(CS 405)-Professor: Qi Hao\n",
    "\n",
    "## Homework #2\n",
    "#### Due date: October, 7th, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries that you might require.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "\n",
    "X = breast['data']\n",
    "y = breast['target']\n",
    "\n",
    "np.random.seed(100)\n",
    "p = np.random.permutation(len(X))\n",
    "X, y = X[p], y[p]\n",
    "\n",
    "X_train, y_train = X[:400], y[:400]\n",
    "X_val, y_val = X[400:500], y[400:500]\n",
    "X_test, y_test = X[500:], y[500:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "17.91"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "X.shape[0]\n",
    "len(X)\n",
    "y\n",
    "type(X[[1,2]])\n",
    "X[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "30"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [2,-1,-1,-1]\n",
    "x = np.square(x)\n",
    "x\n",
    "X_train[:,1]\n",
    "for i,item in enumerate(X_train):\n",
    "    for j,item in enumerate(X_train[i,:]):\n",
    "        neighbors = j\n",
    "neighbors\n",
    "len(X_train[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the KNN algorithm for the breast cancer dataset. Refer to the pdf and the following functions for the instructions. Complete all the functions as indicated below. The four functions would be autograded as mentioned in the pdf."
   ]
  },
  {
   "source": [
    "The L1 norm that is calculated as the sum of the absolute values of the vector.  \n",
    "The L2 norm that is calculated as the square root of the sum of the squared vector values.  \n",
    "The max norm that is calculated as the maximum vector values.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = computeDistancesNeighbors(1, \"L2\", X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1, 2, 3],\n       [1, 3, 6]])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X = np.array([[1,2,3],[1,3,6]])\n",
    "y = np.array([1,0])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "36"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "\n",
    "neighbors = computeDistancesNeighbors(1, \"L2\", X, y, 1)\n",
    "len(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-9bf645c88796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtwo_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "two_d = np.array([[1, 2], [4, 5]])\n",
    "# for x,y in X_val:\n",
    "#     pass\n",
    "\n",
    "# print(type(X_train))\n",
    "# type(two_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 1: Classification\n",
    "\n",
    "Please implement KNN for K: 3, 5, and 7 with the following norms:\n",
    "L1\n",
    "L2\n",
    "L-inf\n",
    "\"\"\"\n",
    "\n",
    "# Read data (Breast Cancer Dataset). Remember to comment out the code not contained in a function.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "\n",
    "X = breast['data']\n",
    "y = breast['target']\n",
    "\n",
    "np.random.seed(100)\n",
    "p = np.random.permutation(len(X))\n",
    "X, y = X[p], y[p]\n",
    "\n",
    "X_train, y_train = X[:400], y[:400]\n",
    "X_val, y_val = X[400:500], y[400:500]\n",
    "X_test, y_test = X[500:], y[500:]\n",
    "\n",
    "\n",
    "def distanceFunc(metric_type, vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes the distance between two d-dimension vectors. \n",
    "    \n",
    "    Please DO NOT use Numpy's norm function when implementing this function. \n",
    "    \n",
    "    Args:\n",
    "        metric_type (str): Metric: L1, L2, or L-inf\n",
    "        vec1 ((d,) np.ndarray): d-dim vector\n",
    "        vec2 ((d,)) np.ndarray): d-dim vector\n",
    "    \n",
    "    Returns:\n",
    "        distance (float): distance between the two vectors\n",
    "    \"\"\"\n",
    "    diff = vec1 - vec2\n",
    "    #diff = list(diff)\n",
    "    if metric_type == \"L1\":\n",
    "        diff_abs = np.abs(diff)\n",
    "        distance = np.sum(diff_abs) #complete\n",
    "\n",
    "    if metric_type == \"L2\":\n",
    "        diff_square = np.square(diff)\n",
    "        distance = np.sqrt(np.sum(diff_square)) #complete\n",
    "        \n",
    "    if metric_type == \"L-inf\":\n",
    "        diff_abs = np.abs(diff)\n",
    "        distance = np.max(diff_abs) #complete\n",
    "        \n",
    "    return distance\n",
    "\n",
    "\n",
    "def computeDistancesNeighbors(K, metric_type, X_train, y_train, sample):\n",
    "    \"\"\"\n",
    "    Compute the distances between every datapoint in the train_data and the \n",
    "    given sample. Then, find the k-nearest neighbors.\n",
    "    \n",
    "    Return a numpy array of the label of the k-nearest neighbors.\n",
    "    \n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        sample ((p,) np.ndarray): Single sample whose distance is to computed with every entry in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "    \"\"\"\n",
    "\n",
    "    # You will also call the function \"distanceFunc\" here\n",
    "    # Complete this function\n",
    "    neighbors = []\n",
    "    for i,item in enumerate(X_train):\n",
    "        for j,item in enumerate(X_train[i,:]):\n",
    "            for i_k,item in enumerate(X_train):\n",
    "                for j_k,item in enumerate(X_train[i,:]):\n",
    "                    vec1 = X_train[i,j]\n",
    "                    vec2 = X_train[i_k,j_k]\n",
    "                    neighbors.append(distanceFunc(\"L1\", vec1, vec2))\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def Majority(neighbors):\n",
    "    \"\"\"\n",
    "    Performs majority voting and returns the predicted value for the test sample.\n",
    "    \n",
    "    Since we're performing binary classification the possible values are [0,1].\n",
    "    \n",
    "    Args:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "        \n",
    "    Returns:\n",
    "        predicted_value (int): predicted label for the given sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # Performs majority voting\n",
    "    # Complete this function\n",
    "\n",
    "    \n",
    "    \n",
    "    return predicted_value\n",
    "\n",
    "\n",
    "def KNN(K, metric_type, X_train, y_train, X_val):\n",
    "    \"\"\"\n",
    "    Returns the predicted values for the entire validation or test set.\n",
    "    \n",
    "    Please DO NOT use Scikit's KNN model when implementing this function. \n",
    "\n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        X_val ((n, p) np.ndarray): Validation or test data\n",
    "        \n",
    "    Returns:\n",
    "        predicted_values (list): output for every entry in validation/test dataset \n",
    "    \"\"\"\n",
    "    \n",
    "    # Complete this function\n",
    "    # Loop through the val_data or the test_data (as required)\n",
    "    # and compute the output for every entry in that dataset  \n",
    "    # You will also call the function \"Majority\" here\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluation(predicted_values, actual_values):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the given datapoints.\n",
    "    \n",
    "    Args:\n",
    "        predicted_values ((n,) np.ndarray): Predicted values for n samples\n",
    "        actual_values ((n,) np.ndarray): Actual values for n samples\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    return accuracy_score(predicted_values, actual_values)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Calls the above functions in order to implement the KNN algorithm.\n",
    "    \n",
    "    Test over the following range K = 3,5,7 and all three metrics. \n",
    "    In total you will have nine combinations to try.\n",
    "    \n",
    "    PRINTS out the accuracies for the nine combinations on the validation set,\n",
    "    and the accuracy on the test set for the selected K value and appropriate norm.\n",
    "    \n",
    "    REMEMBER: You have to report these values by populating the Table 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Complete this function\n",
    "    \n",
    "    K = [3,5,7]\n",
    "    norm = [\"L1\", \"L2\", \"L-inf\"]\n",
    "    \n",
    "    print(\"<<<<VALIDATION DATA PREDICTIONS>>>>\")\n",
    "    \n",
    "    ## Complete\n",
    "    \n",
    "    print(\"<<<<TEST DATA PREDICTIONS>>>>\")\n",
    "    \n",
    "    ## Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassfier(object):\n",
    "\n",
    "    def __init__(self, k=5, distance='euc'):\n",
    "        self.k = k\n",
    "        self.distance = distance\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def fit(self,X, Y):\n",
    "        '''\n",
    "        X : array-like [n_samples,shape]\n",
    "        Y : array-like [n_samples,1]\n",
    "        '''        \n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        '''\n",
    "        X_test : array-like [n_samples,shape]\n",
    "        Y_test : array-like [n_samples,1]\n",
    "        output : array-like [n_samples,1]\n",
    "        '''  \n",
    "        all_dis = []\n",
    "        output = np.zeros((X_test.shape[0],1))\n",
    "        for i in range(X_test.shape[0]):\n",
    "            dis = [] \n",
    "            for j in range(self.x.shape[0]):\n",
    "                if self.distance == 'euc': # 欧式距离\n",
    "                    dis.append(np.linalg.norm(X_test[i,:]-self.x[j,:]))\n",
    "            all_dis.append(dis)\n",
    "\n",
    "            labels = []\n",
    "            index=sorted(range(len(dis)), key=dis.__getitem__)\n",
    "            for j in range(self.k):\n",
    "                labels.append(self.y[index[j]])\n",
    "            print(labels)\n",
    "\n",
    "            counts = []\n",
    "            for label in labels:\n",
    "                counts.append(labels.count(label))\n",
    "\n",
    "\n",
    "            output[i] = labels[np.argmax(counts)]\n",
    "        print(len(dis))\n",
    "        print(len(X_test))\n",
    "        return output,all_dis\n",
    "    \n",
    "\n",
    "    def score(self,pred,y):\n",
    "       # pred = self.predict(x)\n",
    "        err = 0.0\n",
    "        for i in range(y.shape[0]):\n",
    "            if pred[i]!=y[i]:\n",
    "                err = err+1\n",
    "        return 1-float(err/y.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[0, 0, 0]\n[0, 0, 0]\n[1, 1, 1]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[0, 0, 0]\n[1, 0, 1]\n[1, 1, 1]\n[1, 0, 1]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 0]\n[1, 1, 1]\n[1, 1, 0]\n[1, 1, 1]\n[0, 0, 0]\n[0, 0, 0]\n[1, 1, 1]\n[0, 0, 0]\n[1, 1, 1]\n[0, 1, 1]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[0, 0, 0]\n[0, 0, 0]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 0]\n[1, 1, 1]\n[0, 0, 0]\n[0, 0, 0]\n[1, 1, 1]\n[0, 0, 0]\n[0, 1, 0]\n[1, 0, 0]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[0, 0, 0]\n[1, 1, 1]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[0, 0, 0]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n[0, 0, 0]\n[1, 1, 0]\n[0, 0, 0]\n[1, 1, 1]\n[1, 1, 1]\n[1, 1, 1]\n400\n69\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8840579710144928"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "clf = KNNClassfier(k=3)\n",
    "clf.fit(X_train,y_train)\n",
    "pred,all_dis = clf.predict(X_test)\n",
    "clf.score(pred,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the code below to run the main function (Remember to recomment the code before submitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(400, 30)\n(69, 30)\n(69, 400)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1228.39208106,  670.46728057, 1678.64724855,  134.97344493,\n        273.08293162,  198.39168617, 1187.48913703, 1838.495648  ,\n        555.06220441,  273.20982015,   28.30869937, 1533.80090613,\n       3324.63776691, 1885.2524455 ,  484.80500112,  791.76149519,\n        840.3141892 ,  453.89104138,   55.19565703,  226.46160004,\n        943.95468909,  360.91255365,  832.47829574, 2362.78435718,\n        594.12647647, 1024.48974181,  247.67154161,   54.97361601,\n        252.3288563 ,  302.61341068,  221.2910329 ,  257.8388386 ,\n        520.00817743, 1084.93719096, 1637.89774871,  225.70579985,\n        400.24194219,  388.0052338 ,  133.54274062, 2398.21623951,\n        816.57090389,  309.15416951,  136.17050514,  739.13104067,\n        517.91786661,  897.26347485,  188.82888323,   27.56218187,\n        224.63585694,   15.60243596,  832.63435619,   35.85542896,\n        612.70571858, 1098.7813116 ,  250.40604248,  499.95360801,\n        472.6615807 ,  275.79638752,   75.18304173,  237.29722927,\n       1855.62589032, 1317.08446345,  321.01083131,  275.78419008,\n       1516.07496282,  412.87763831, 1442.28861049, 3403.08141435,\n        383.64999979, 1685.79205202, 1697.21653404,  478.87911348,\n        572.12668493, 2407.73463836,  250.92321988,  565.47829536,\n        825.60879266, 1667.96584169, 1684.98489178,  335.870259  ,\n        615.45992435,  750.7160118 , 1142.96139112,  919.18683043,\n         67.20863788, 1368.4760449 , 4558.59783758,  230.03321921,\n       2040.43644278,  223.00210474,  190.01222873,  364.14204626,\n        472.94698175, 1904.86686199,  208.91443902,  881.18048709,\n        860.51688262,  171.31522869, 2031.81375807,  808.74801334,\n        795.8540328 , 1789.31871341,  273.29316584,  340.89870628,\n        649.45797433,  520.47364008,   39.27970096,  783.23436466,\n        123.28848353,  116.00278633, 1121.56466687,  346.0307164 ,\n       1503.69065348,   62.00268994,  402.92855311,  373.81111877,\n        776.79136133,  277.10399137,  359.70938157,  242.87162919,\n       1982.25465076,  303.04033524,  281.30700639, 1579.23215846,\n        392.45169798,  203.10379019,  457.38292131,  722.45960015,\n        308.16836413,   86.71813134,  110.03326815,  338.95117612,\n       1416.61673888,  235.64664778,  485.57331629,  969.24135197,\n        232.70151168,  628.07933199,  212.88951265,  378.21975219,\n        746.30283257, 1631.52622386,  479.22184257,  301.55744141,\n        490.85657165,   71.70837767,  221.02274584,  692.16837411,\n       1952.67424392,  193.81593193,  550.10294513,  650.25798065,\n        737.13586216, 1870.51991974,  655.46940774,  863.67406182,\n        563.22765871, 2564.63877868,   75.31418305,  403.27030367,\n         79.02346614,  503.35589079,  514.24251986,  646.87602018,\n         61.34406155,  270.25567127,  667.33343044,  657.08650983,\n        413.99805472, 1537.74977293,  459.64253817, 2307.25116072,\n        982.94608278,  550.03804642,  358.42805715,  522.263248  ,\n        311.04888997,  337.65558032,  169.28975872,  499.86507345,\n         33.28639052,  646.24933181,  235.71528255,  292.72442757,\n         39.12450744, 1214.97725405,  477.90377843,   65.37193366,\n        609.18301669,  696.96487324,   85.55962593, 1634.22291163,\n        373.00616846,   47.76690022,  391.06556112, 1075.77681502,\n       1233.73684065,  102.90710849,  256.23160728,   93.88375042,\n        635.79780103,  781.92701308,  494.89119403,  180.64867044,\n       1093.75984366, 1059.71072962,  185.21463784, 1508.8144246 ,\n       1762.16612658,  759.2143174 ,  451.21201606,  572.71471655,\n        257.63349902, 1744.50642015,  167.50577624,  671.31102864,\n       1574.93585283,  643.92589526, 2102.13265176,   20.64871357,\n        313.44291008,  173.36192558,  454.41841623,  291.06808752,\n        415.18860243,  426.75753369,  723.8089577 ,   67.95605904,\n        263.88051256,  325.7881215 ,  368.63430971, 1061.34628874,\n       1272.56218945, 2982.03896846,  305.62236663,  293.91744192,\n       1809.21186936,  612.38077873,  322.47623197,  686.34510015,\n        197.21135829,  301.45443817, 1490.61060976,  613.8519626 ,\n       2102.59702833,  471.40525232,  100.57949045,  866.29980392,\n       2986.62814322,  208.88710745,  113.95980924, 1502.28051898,\n        515.77233146, 3107.72227747,   92.52248439,  767.95309449,\n        156.21991003, 1476.63474672,  246.60610232, 1129.22741325,\n        183.24781853,  177.44468047,   58.51945579,   52.31676569,\n        282.01079022,  402.46919259,  393.43727076,  236.9206501 ,\n        313.99661627,  973.18120943,  499.00518628,  898.5602572 ,\n        666.32049383, 2194.77704242,  503.88593005,  651.00431912,\n         36.78517443,  185.4733551 ,  595.55392213,   70.31178205,\n        556.55611695,  442.81841815,  987.64662144,  209.20201711,\n        405.48791755,   71.96997752,  491.41064033,   63.39114213,\n         24.94887219,   96.04794601,  463.87815378, 1145.77493695,\n       1481.38873432, 1335.79114396,  471.392741  ,  196.51218681,\n       1015.58175895,  650.58926936,  692.65076217,  633.27519484,\n        401.75088345,  170.56220002, 1789.25104415,  514.39065215,\n        313.31010913,  297.79341215,  242.75150364, 1879.46291671,\n        133.42005814,  186.2196433 ,  620.70038284,  629.37177678,\n        728.67183987,  251.64085525,  365.89543122,  418.43308872,\n        288.13516095,  254.79949747,  605.99727556,  522.1515315 ,\n        607.66973035,  148.16233284,  540.35432569,  213.18551744,\n        211.56386104,  125.34948546,  327.77489033, 1207.00811716,\n        219.55653631,  121.96786867,  360.74493396,  569.71636824,\n         71.10079566,  209.58943582,  134.58900187,   45.17922789,\n       2848.32756003,  279.0658697 ,  326.70026301,  315.06019956,\n       1173.00105084, 1520.50841184, 1150.09219888, 2525.86988841,\n        270.40189581,  365.34495284,  332.63209524,  220.40671136,\n        167.22703816, 2813.00236731, 2137.24009651,  180.39854203,\n        874.74091987,  296.68103802, 1152.05490563, 1774.94493639,\n        416.94230008,  350.4248119 ,   33.5800878 , 1047.73194815,\n        319.05550601,   91.02880774,  416.57648587,  536.53033992,\n        260.35587527,  396.9479814 ,  158.85460483, 1579.46505543,\n        368.8638728 , 1311.81362485,  428.90429842, 1514.58937059,\n        253.46015053,  164.52033349,  137.69989782,   92.88677451,\n        621.7293392 ,  496.32078638,  458.12002109,  489.88826987,\n        198.57201495,  351.32166108, 1537.26947584,  208.199906  ,\n        657.76610779,  520.43852835, 1657.5492771 ,  600.64930985,\n        183.67371288, 1107.86133616,  319.46435181,  449.12748329,\n        408.43450298,  620.81567413,  269.17581765, 1949.8449764 ,\n        391.81509674,   74.50433113,  381.45350354, 2768.80833318])"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# Finally, call the main function\n",
    "# main()\n",
    "len(all_dis)\n",
    "len(X_train)\n",
    "print(X_train.shape[:])\n",
    "print(X_test.shape[:])\n",
    "all_dis = np.array(all_dis)\n",
    "print(all_dis.shape[:])\n",
    "all_dis[68,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "483.64673633137875\n483.64673633137875\n"
    }
   ],
   "source": [
    "diff = X_test[1,:]-X_train[1,:]\n",
    "diff_square = np.square(diff)\n",
    "distance = np.sqrt(np.sum(diff_square))\n",
    "\n",
    "distance\n",
    "distance2 = np.linalg.norm(X_test[1,:]-X_train[1,:])\n",
    "print(distance)\n",
    "print(distance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1228.3920810612967,\n 670.4672805671959,\n 1678.6472485492206,\n 134.9734449305453,\n 273.0829316178607,\n 198.3916861711877,\n 1187.4891370257158,\n 1838.4956480048447,\n 555.0622044111343,\n 273.2098201510702,\n 28.308699373654125,\n 1533.8009061341074,\n 3324.6377669055328,\n 1885.2524454969173,\n 484.8050011209675,\n 791.7614951892691,\n 840.3141891968595,\n 453.8910413758823,\n 55.1956570317644,\n 226.46160004003997,\n 943.9546890883832,\n 360.91255365183883,\n 832.4782957417731,\n 2362.7843571766866,\n 594.1264764664473,\n 1024.4897418058852,\n 247.67154161280672,\n 54.973616014463786,\n 252.32885629893084,\n 302.61341067970943,\n 221.29103290113477,\n 257.8388385954318,\n 520.0081774256548,\n 1084.9371909590309,\n 1637.897748714578,\n 225.7057998514512,\n 400.241942192181,\n 388.0052337966568,\n 133.54274061519948,\n 2398.2162395143814,\n 816.5709038865108,\n 309.15416950606044,\n 136.17050513712016,\n 739.1310406719138,\n 517.9178666098818,\n 897.2634748504563,\n 188.82888323372245,\n 27.562181871414477,\n 224.6358569386266,\n 15.602435957133126,\n 832.6343561894911,\n 35.855428956697686,\n 612.7057185826063,\n 1098.781311602962,\n 250.4060424797641,\n 499.9536080085083,\n 472.6615806980031,\n 275.79638752071895,\n 75.18304172604961,\n 237.2972292682434,\n 1855.625890322705,\n 1317.084463451406,\n 321.0108313135965,\n 275.7841900819744,\n 1516.0749628193987,\n 412.87763831307547,\n 1442.288610493736,\n 3403.081414349353,\n 383.64999978622,\n 1685.792052017536,\n 1697.216534043095,\n 478.87911347878355,\n 572.1266849340296,\n 2407.734638364979,\n 250.92321987802757,\n 565.4782953633429,\n 825.608792664271,\n 1667.9658416927994,\n 1684.984891777024,\n 335.87025900311414,\n 615.4599243518602,\n 750.7160118019492,\n 1142.9613911161523,\n 919.1868304282215,\n 67.20863787707954,\n 1368.4760449001617,\n 4558.5978375762925,\n 230.0332192087669,\n 2040.4364427750959,\n 223.00210474278438,\n 190.01222872757276,\n 364.1420462610849,\n 472.94698175289744,\n 1904.8668619900789,\n 208.91443902027555,\n 881.1804870906997,\n 860.516882624273,\n 171.31522868596463,\n 2031.8137580689151,\n 808.7480133412134,\n 795.8540327960867,\n 1789.3187134054185,\n 273.29316584360373,\n 340.8987062839547,\n 649.4579743333113,\n 520.4736400803727,\n 39.27970096135882,\n 783.2343646567454,\n 123.28848352716611,\n 116.00278632623386,\n 1121.5646668691113,\n 346.03071639942124,\n 1503.690653480169,\n 62.002689937100556,\n 402.9285531141969,\n 373.81111876694894,\n 776.7913613317061,\n 277.10399136519015,\n 359.70938156593047,\n 242.87162918583513,\n 1982.2546507620877,\n 303.04033524170364,\n 281.30700638890613,\n 1579.2321584570443,\n 392.45169798427224,\n 203.1037901883149,\n 457.382921312304,\n 722.4596001523464,\n 308.1683641327886,\n 86.71813134058021,\n 110.03326815198811,\n 338.951176123828,\n 1416.6167388801055,\n 235.6466477847137,\n 485.5733162901224,\n 969.2413519690444,\n 232.7015116801515,\n 628.0793319865521,\n 212.88951264966136,\n 378.2197521889287,\n 746.3028325723371,\n 1631.5262238638925,\n 479.22184257463596,\n 301.5574414116098,\n 490.85657164916813,\n 71.70837767328388,\n 221.0227458421215,\n 692.1683741089174,\n 1952.6742439195568,\n 193.81593193482237,\n 550.1029451269502,\n 650.2579806467741,\n 737.1358621599038,\n 1870.5199197365323,\n 655.4694077412091,\n 863.6740618165887,\n 563.2276587101348,\n 2564.638778682869,\n 75.31418304534215,\n 403.2703036699269,\n 79.0234661436236,\n 503.35589079228055,\n 514.242519860336,\n 646.8760201849857,\n 61.34406155407561,\n 270.2556712710209,\n 667.3334304385553,\n 657.086509827556,\n 413.9980547200322,\n 1537.7497729347174,\n 459.642538170951,\n 2307.2511607152173,\n 982.9460827756086,\n 550.0380464233501,\n 358.4280571508483,\n 522.2632480034414,\n 311.0488899694864,\n 337.6555803157305,\n 169.28975871907858,\n 499.8650734498419,\n 33.2863905238456,\n 646.2493318086613,\n 235.71528254926966,\n 292.72442756951773,\n 39.12450743868213,\n 1214.977254052227,\n 477.90377842562623,\n 65.37193366441286,\n 609.1830166875249,\n 696.9648732424345,\n 85.55962593428745,\n 1634.2229116321244,\n 373.006168462434,\n 47.766900217722785,\n 391.06556111845697,\n 1075.7768150223435,\n 1233.7368406547057,\n 102.90710848887102,\n 256.2316072837362,\n 93.8837504219644,\n 635.7978010258694,\n 781.9270130792804,\n 494.8911940341696,\n 180.64867044360594,\n 1093.759843659655,\n 1059.7107296205363,\n 185.21463784280542,\n 1508.8144246028205,\n 1762.1661265775917,\n 759.2143173970857,\n 451.21201605965314,\n 572.7147165472499,\n 257.63349902443485,\n 1744.506420146849,\n 167.50577624258062,\n 671.3110286431211,\n 1574.9358528304354,\n 643.9258952617795,\n 2102.1326517550287,\n 20.648713568598044,\n 313.44291007596433,\n 173.3619255825515,\n 454.41841623465746,\n 291.06808752313265,\n 415.1886024291988,\n 426.7575336875784,\n 723.808957702636,\n 67.9560590370996,\n 263.88051255699617,\n 325.7881215035477,\n 368.63430970784907,\n 1061.3462887430612,\n 1272.5621894526928,\n 2982.0389684634924,\n 305.62236663080506,\n 293.91744191796613,\n 1809.2118693592442,\n 612.3807787334181,\n 322.4762319718626,\n 686.3451001515269,\n 197.21135828821522,\n 301.45443817421085,\n 1490.61060976082,\n 613.8519626015479,\n 2102.5970283348415,\n 471.40525232132245,\n 100.57949045411662,\n 866.2998039244115,\n 2986.6281432198703,\n 208.88710744775054,\n 113.95980923677658,\n 1502.2805189807186,\n 515.7723314591204,\n 3107.722277469605,\n 92.52248438651773,\n 767.953094486713,\n 156.21991003027264,\n 1476.6347467155877,\n 246.60610232069106,\n 1129.2274132525558,\n 183.24781853293214,\n 177.44468046646188,\n 58.519455790312946,\n 52.316765694060884,\n 282.01079021609314,\n 402.46919258997,\n 393.4372707551366,\n 236.92065009561324,\n 313.9966162690181,\n 973.1812094314481,\n 499.0051862754474,\n 898.5602571984313,\n 666.3204938299796,\n 2194.777042423039,\n 503.885930053216,\n 651.0043191179311,\n 36.7851744299213,\n 185.47335510006576,\n 595.553922126251,\n 70.31178205150464,\n 556.5561169486272,\n 442.81841815260026,\n 987.6466214422842,\n 209.20201710672845,\n 405.48791755004464,\n 71.96997752067003,\n 491.4106403277424,\n 63.39114213192297,\n 24.94887219197192,\n 96.04794600694355,\n 463.8781537831464,\n 1145.7749369527671,\n 1481.3887343202314,\n 1335.791143960706,\n 471.3927409981427,\n 196.51218680764333,\n 1015.5817589458387,\n 650.589269363761,\n 692.6507621707602,\n 633.2751948421278,\n 401.75088344861757,\n 170.56220001942162,\n 1789.251044151053,\n 514.3906521470423,\n 313.31010912568956,\n 297.7934121493755,\n 242.75150364264974,\n 1879.4629167070418,\n 133.4200581422433,\n 186.21964330388138,\n 620.7003828403135,\n 629.3717767793584,\n 728.671839871661,\n 251.64085525103263,\n 365.89543121690076,\n 418.4330887206054,\n 288.13516095349394,\n 254.7994974726982,\n 605.997275563746,\n 522.1515315008362,\n 607.6697303462917,\n 148.16233283769026,\n 540.354325685022,\n 213.18551744335704,\n 211.56386103944263,\n 125.34948545958135,\n 327.77489032676107,\n 1207.0081171563656,\n 219.5565363075896,\n 121.96786867355038,\n 360.7449339560037,\n 569.7163682398005,\n 71.10079566176493,\n 209.58943582333785,\n 134.58900186541538,\n 45.17922789225536,\n 2848.327560025611,\n 279.0658697010316,\n 326.70026300547846,\n 315.0601995623449,\n 1173.0010508396108,\n 1520.508411840768,\n 1150.0921988835016,\n 2525.869888411158,\n 270.4018958064297,\n 365.3449528434146,\n 332.6320952433508,\n 220.4067113611921,\n 167.22703815923123,\n 2813.0023673075175,\n 2137.2400965088273,\n 180.39854203337444,\n 874.7409198687906,\n 296.68103801864555,\n 1152.0549056263744,\n 1774.9449363884523,\n 416.9423000784161,\n 350.42481190153273,\n 33.58008780454871,\n 1047.7319481519783,\n 319.05550601073134,\n 91.02880773913978,\n 416.5764858686577,\n 536.5303399160974,\n 260.3558752728874,\n 396.94798140344193,\n 158.8546048290158,\n 1579.4650554273408,\n 368.8638728022791,\n 1311.8136248462079,\n 428.9042984194344,\n 1514.5893705902133,\n 253.46015052857098,\n 164.52033348922558,\n 137.6998978231945,\n 92.88677451302513,\n 621.7293392037909,\n 496.320786376447,\n 458.1200210919628,\n 489.88826987363814,\n 198.57201495455436,\n 351.32166108215483,\n 1537.269475836165,\n 208.19990600348956,\n 657.7661077926616,\n 520.4385283478358,\n 1657.5492770986234,\n 600.6493098494403,\n 183.6737128812251,\n 1107.8613361601815,\n 319.4643518060669,\n 449.1274832880559,\n 408.43450298035793,\n 620.8156741327549,\n 269.1758176483727,\n 1949.8449764002246,\n 391.81509673789185,\n 74.50433112983544,\n 381.4535035426126,\n 2768.808333178748]"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    dis = [] \n",
    "    for j in range(X_train.shape[0]):\n",
    "        # dis.append(np.linalg.norm(X_test[i,:]-X_train[j,:]))\n",
    "        diff = X_test[i,:]-X_train[j,:]\n",
    "        diff_square = np.square(diff)\n",
    "        distance = np.sqrt(np.sum(diff_abs))\n",
    "\n",
    "    #all_dis.append(dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions here:\n",
    "\n",
    "1. How could having a larger dataset influence the performance of KNN?\n",
    "\n",
    "2. Tabulate your results from `main()` in the table provided.\n",
    "\n",
    "3. Finally, mention the best K and the norm combination you have settled upon and report the accuracy on the test set using that combination."
   ]
  },
  {
   "source": [
    "Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceFunc(metric_type, vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes the distance between two d-dimension vectors. \n",
    "    \n",
    "    Please DO NOT use Numpy's norm function when implementing this function. \n",
    "    \n",
    "    Args:\n",
    "        metric_type (str): Metric: L1, L2, or L-inf\n",
    "        vec1 ((d,) np.ndarray): d-dim vector\n",
    "        vec2 ((d,)) np.ndarray): d-dim vector\n",
    "    \n",
    "    Returns:\n",
    "        distance (float): distance between the two vectors\n",
    "    \"\"\"\n",
    "    diff = vec1 - vec2\n",
    "    #diff = list(diff)\n",
    "    if metric_type == \"L1\":\n",
    "        diff_abs = np.abs(diff)\n",
    "        distance = np.sum(diff_abs) #complete\n",
    "\n",
    "    if metric_type == \"L2\":\n",
    "        diff_square = np.square(diff)\n",
    "        distance = np.sqrt(np.sum(diff_square)) #complete\n",
    "        \n",
    "    if metric_type == \"L-inf\":\n",
    "        diff_abs = np.abs(diff)\n",
    "        distance = np.max(diff_abs) #complete\n",
    "        \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.]\n [1.]\n [1.]\n [1.]]\n"
    }
   ],
   "source": [
    "X = np.array([[1,9,3],[1,3,6],[5,5,5],[7,7,8]])\n",
    "y = np.array([1,0,1,1])\n",
    "distance1 = []\n",
    "distance2 = []\n",
    "len_X = X.shape[0]\n",
    "X_idx = X\n",
    "output = np.zeros((X.shape[0],1))\n",
    "for i in range(len_X):\n",
    "    dis = []\n",
    "    for j in (range(len_X)):\n",
    "        dis1 = np.linalg.norm(X[i,:]-X_idx[(j),:])\n",
    "        dis.append(dis1)\n",
    "    #print(dis)\n",
    "\n",
    "    labels = []\n",
    "    index=sorted(range(len(dis)), key=dis.__getitem__)\n",
    "\n",
    "\n",
    "    labels = []\n",
    "    for j in range(3):\n",
    "        labels.append(y[index[j]])\n",
    "    \n",
    "\n",
    "    counts = []\n",
    "    for label in labels:\n",
    "        counts.append(labels.count(label))\n",
    "    output[i] = labels[np.argmax(counts)]\n",
    "print(output)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#print(dis)\n",
    "\n",
    "# for i,item in enumerate(X):\n",
    "#     for j,item in enumerate(X[i]):\n",
    "#         for i_k,item in enumerate(X):\n",
    "#             for j_k,item in enumerate(X[i_k]):\n",
    "#                 vec1 = X[i][j]\n",
    "#                 vec2 = X[i_k][j_k]\n",
    "#                 distance1.append(distanceFunc(\"L1\", vec1, vec2))\n",
    "                #distance2.append(np.linalg.norm(vec1,vec2))\n",
    "# distanceFunc(\"L1\", vec1, vec2)\n",
    "# np.linalg.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1, 1, 0]"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "#dis = [6.0, 4.58257569495584, 0.0, 4.123105625617661]\n",
    "# dis = [20,16,12,13]\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "range(0, 4)"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "range(len(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1, 1, 0]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1]"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-df90b5bf8779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnewgrades\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewgrades\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "students = [10,20,30]\n",
    "newgrades = [4,2,3]\n",
    "sorted(students, key=newgrades.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "X[1][1] - X[0][0]\n",
    "np.linalg.norm(vec1-vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(150, 4)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x.shape[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([4.9, 3. , 1.4, 0.2])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "x[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(400, 30)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "X_train.shape[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}